{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reqs\n",
    "\n",
    "import pandas, prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "# utils\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "plt = matplotlib.pyplot\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 8]\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'\n",
    "import torch\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data\n",
    "\n",
    "loads from data/observations.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jaismith/Developer/personal/flowcast/learn.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=0'>1</a>\u001b[0m observations \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m'\u001b[39m\u001b[39moutput/observations.pickle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39m# print(observations.head())\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39m# # to make this data better suited for regression, we'll run it through savitzky golay to smooth\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39m# observations = observations.apply(lambda d: savgol_filter(d, 25, 3))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=12'>13</a>\u001b[0m \u001b[39m# observations.head(4 * 24).plot()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=13'>14</a>\u001b[0m \u001b[39m# plt.show()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=15'>16</a>\u001b[0m observations \u001b[39m=\u001b[39m observations\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(observations\u001b[39m.\u001b[39mhead())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=18'>19</a>\u001b[0m \u001b[39m# prep for prophet\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000003?line=19'>20</a>\u001b[0m \u001b[39m# to make this data better suited for regression, we'll run it through savitzky golay to smooth\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/prophet/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/prophet/lib/python3.9/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   4955\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   4956\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4957\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4958\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   4959\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4960\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   4961\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   4962\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/prophet/lib/python3.9/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4269\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/prophet/lib/python3.9/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/prophet/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "observations = pd.read_pickle('output/observations.pickle')\n",
    "print(observations.head())\n",
    "# to make this data better suited for regression, we'll run it through savitzky golay to smooth\n",
    "observations = observations.apply(lambda d: savgol_filter(d, 25, 3))\n",
    "\n",
    "# for readability, rename 107337_00065 -> gageheight, 107338_00010 -> watertemp\n",
    "observations = observations.rename(columns={'107337_00065': 'gageheight', '107338_00010': 'watertemp'})\n",
    "\n",
    "# [temp] to simplify, drop gageheight and reduce num observations\n",
    "observations = observations.drop(columns=['gageheight'])\n",
    "\n",
    "print(observations.head())\n",
    "observations.head(4 * 24).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds   airtemp  cloudcover  precip         y\n",
      "0 2008-01-01 06:15:00 -7.274530    2.741197     0.0  1.943590\n",
      "1 2008-01-01 06:30:00 -7.352735    2.464017     0.0  1.918974\n",
      "2 2008-01-01 06:45:00 -7.365834    2.229257     0.0  1.895998\n",
      "3 2008-01-01 07:00:00 -7.319631    2.035260     0.0  1.874504\n",
      "4 2008-01-01 07:15:00 -7.219930    1.880372     0.0  1.854337\n",
      "(390224, 5) (97556, 5)\n"
     ]
    }
   ],
   "source": [
    "# water temp -> y, index -> ds\n",
    "observations = observations.reset_index()\n",
    "observations = observations.rename(columns={'watertemp': 'y', 'index': 'ds'})\n",
    "\n",
    "# remove timezone\n",
    "observations['ds'] = observations['ds'].dt.tz_localize(None)\n",
    "\n",
    "print(observations.head())\n",
    "\n",
    "# split df\n",
    "cutoff = int(observations.shape[0] * 0.80)\n",
    "train = observations.iloc[:cutoff, :]\n",
    "test = observations.iloc[cutoff:, :]\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/prophet/lib/python3.9/site-packages/prophet/forecaster.py:896: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  components = components.append(new_comp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -25424.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x11111f850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "Error evaluating model log probability: Non-finite gradient.\n",
      "\n",
      "      99        874952   0.000796825        178992           1           1      139   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        877682     0.0111749        431030      0.2254           1      266   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        882643    0.00221847        527191           1           1      386   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        883348   0.000394125        247686           1           1      515   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        885226     0.0289053        103525           1           1      645   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        894631     0.0272805        171528     0.04752           1      778   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        895747    0.00134774       95263.9           1           1      901   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        896615   0.000347367       56512.8      0.3149      0.3149     1027   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899        897395     0.0124579        177827       1.647      0.1647     1151   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999        899062    0.00115461        124353           1           1     1280   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        900115   0.000286541       50044.4           1           1     1399   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199        900706    0.00144107        102296       2.448      0.2448     1528   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299        901456   0.000978979        141845           1           1     1651   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399        901855    0.00312689        156398           1           1     1771   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499        902325    0.00176162         63251     0.03699      0.8739     1899   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599        903139    0.00232862       72983.7           1           1     2032   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699        903538    0.00160358        241757           1           1     2150   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1799        904004     0.0060613        121219           1           1     2268   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1899        904443   0.000890469       91365.8           1           1     2387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1999        904933   0.000762719        146055      0.1589      0.1589     2509   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2099        905130   0.000983686        131518           1           1     2633   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2199        905258    0.00101059       39298.5       2.501      0.2501     2759   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2299        905352   0.000324999       32056.6      0.4738           1     2883   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2399        905628   0.000701988         40472           1           1     3018   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2499        905835    0.00414911        249145           1           1     3139   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2599        905993    0.00117528       87685.9           1           1     3253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2699        906087    0.00507162       36108.6           1           1     3388   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2799        906191   0.000652487       45998.1      0.4515      0.4515     3513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2899        906252   0.000375347       21408.2           1           1     3638   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2999        906321   0.000116213       91323.9      0.3777      0.3777     3757   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3099        906370   6.19132e-05        9584.3      0.9836      0.9836     3877   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3199        906406   0.000542917       11087.5           1           1     3997   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3299        906468    0.00213052       33878.7      0.5763     0.05763     4130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3399        906512    0.00156035        121958           1           1     4252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3499        906529   0.000205367       55892.4           1           1     4378   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3599        906568   0.000369181       72954.8        0.31           1     4508   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3699        906601    0.00226761       81986.7      0.6623      0.6623     4628   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3799        906712   0.000159768       34266.3     0.04259           1     4767   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3899        906886    0.00918868        375641      0.5241           1     4885   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    3999        906982    0.00224576       81620.3           1           1     5007   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4099        907067   0.000581144        241898           1           1     5127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4199        907143   0.000233568       9755.27           1           1     5262   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4299        907214   0.000477466       21409.4      0.1523           1     5392   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4399        907240   0.000753376       11646.2       0.838      0.0838     5518   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4499        907250   0.000537257       94069.9           1           1     5661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4599        907270   0.000918143       36719.8      0.2969      0.2969     5785   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4699        907289   8.36873e-05       5040.83     0.04459           1     5911   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    4719        907290   2.27876e-05       3010.05           1           1     5940   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "model = Prophet(yearly_seasonality=True, daily_seasonality=True, weekly_seasonality=False)\n",
    "model.add_regressor('airtemp', standardize=False)\n",
    "model.add_regressor('cloudcover', standardize=False)\n",
    "model.add_regressor('precip', standardize=False)\n",
    "\n",
    "# fit\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jaismith/Developer/personal/flowcast/learn.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39m# forecast one week\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000007?line=1'>2</a>\u001b[0m week \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mtail(\u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m24\u001b[39m \u001b[39m*\u001b[39m \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mappend(test\u001b[39m.\u001b[39mhead(\u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m24\u001b[39m \u001b[39m*\u001b[39m \u001b[39m200\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000007?line=3'>4</a>\u001b[0m \u001b[39m# compare\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaismith/Developer/personal/flowcast/learn.ipynb#ch0000007?line=4'>5</a>\u001b[0m actual \u001b[39m=\u001b[39m week\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# forecast one week\n",
    "week = train.tail(4 * 24 * 3).append(test.head(4 * 24 * 28))\n",
    "\n",
    "# compare\n",
    "actual = week\n",
    "\n",
    "# # 3 days historical\n",
    "# historical = week.iloc[:4 * 24 * 3, :]\n",
    "# projected = week.iloc[4 * 24 * 3:, :][['ds', 'airtemp', 'cloudcover', 'precip']]\n",
    "# combined = historical.append(projected)\n",
    "# print(combined)\n",
    "\n",
    "forecast = model.predict(week[['ds', 'airtemp', 'cloudcover', 'precip']])\n",
    "predicted = forecast\n",
    "\n",
    "print(actual, predicted)\n",
    "\n",
    "# plot weather conditions\n",
    "plt.plot(week['ds'], week['airtemp'])\n",
    "plt.plot(week['ds'], week['cloudcover'])\n",
    "plt.plot(week['ds'], week['precip'])\n",
    "plt.legend(['airtemp', 'cloudcover', 'precip'])\n",
    "plt.show()\n",
    "\n",
    "# plot water temp forecast\n",
    "plt.axvline(x=week['ds'].values[4 * 24 * 3], color='gray')\n",
    "plt.plot(actual['ds'], actual['y'], color='black')\n",
    "plt.plot(predicted['ds'], predicted['yhat'], color='blue')\n",
    "plt.fill_between(predicted['ds'], predicted['yhat_lower'], predicted['yhat_upper'], color='blue', alpha=0.15)\n",
    "plt.legend(['horizon', 'actual', 'forecast'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO()\n",
    "torch.save(model, buffer)\n",
    "# with open('output/model.json', 'w+') as f:\n",
    "  # f.write(model_to_json(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('prophet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcd95ccd486d0ad6291d0bcb0605a6e43bfdf1111600cb0ad962f000ce89d9cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
